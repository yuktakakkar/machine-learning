{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " Q1. Import MNIST dataset from sklearn. \n",
    "     Save data and targets in variables X and Y respectively. \n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits \n",
    "digit = load_digits()\n",
    "x=(digit.data)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "y=(digit.target)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.33501649 -0.04308102 ... -1.14664746 -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649 -1.09493684 ...  0.54856067 -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649 -1.09493684 ...  1.56568555  1.6951369\n",
      "  -0.19600752]\n",
      " ...\n",
      " [ 0.         -0.33501649 -0.88456568 ... -0.12952258 -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649 -0.67419451 ...  0.8876023  -0.5056698\n",
      "  -0.19600752]\n",
      " [ 0.         -0.33501649  1.00877481 ...  0.8876023  -0.26113572\n",
      "  -0.19600752]]\n"
     ]
    }
   ],
   "source": [
    "#Q2. Perform feature scaling.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_SS=StandardScaler().fit_transform(x)\n",
    "print(x_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. Split data into training and testing sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train, y_test = train_test_split(x_SS , y ,test_size = 0.4, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12163885 0.09123035 0.08472444 0.06388294 0.0494201  0.04282851\n",
      " 0.04102182 0.03786929 0.03517134 0.02972145 0.02839352 0.02687796\n",
      " 0.02477528 0.02439225 0.02168395 0.01990376 0.01790314 0.01690855\n",
      " 0.01542958 0.01458062 0.01398432 0.01166788 0.01033306 0.00984864\n",
      " 0.0093835  0.00906151 0.00857963 0.00791684 0.0076653  0.00728933\n",
      " 0.00700228 0.00653761 0.00626391 0.00590292 0.00537454 0.00497408\n",
      " 0.00438788 0.0042681  0.00408694 0.00385854 0.0034617 ]\n"
     ]
    }
   ],
   "source": [
    "#Q4. Perform PCA. Take any value for components. \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.96 )\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5. Perform classification (logistic regression).\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541029207232267\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Q6.  Print the following:\n",
    "        a. Accuracy score\n",
    "        b. Confusion Matrix\n",
    "        c. Classification Report\n",
    "''' \n",
    "prediction = log.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test , prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 72  0  1  0  0  0  0  1  1]\n",
      " [ 0  0 63  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 73  0  3  0  1  3  0]\n",
      " [ 0  1  0  0 72  0  0  1  0  1]\n",
      " [ 1  0  0  0  0 70  0  0  0  0]\n",
      " [ 0  0  0  0  2  0 69  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 78  0  1]\n",
      " [ 0  2  0  0  0  1  1  1 58  1]\n",
      " [ 0  1  0  0  0  1  0  1  6 68]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test , prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.984     1.000     0.992        63\n",
      "          1      0.947     0.960     0.954        75\n",
      "          2      1.000     1.000     1.000        63\n",
      "          3      0.973     0.912     0.942        80\n",
      "          4      0.973     0.960     0.966        75\n",
      "          5      0.933     0.986     0.959        71\n",
      "          6      0.986     0.972     0.979        71\n",
      "          7      0.951     0.975     0.963        80\n",
      "          8      0.853     0.906     0.879        64\n",
      "          9      0.944     0.883     0.913        77\n",
      "\n",
      "avg / total      0.955     0.954     0.954       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test , prediction,labels = None, digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
